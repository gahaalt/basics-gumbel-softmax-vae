{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, re\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(w):\n",
    "    w = re.sub(r\"[^a-zA-Z.!,?ążźśęćńół']+\", \" \", w)\n",
    "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "    \n",
    "    words = []\n",
    "    for word in w.split():\n",
    "        if word[0].isupper():\n",
    "            words.append('<up>')\n",
    "        words.append(word.lower())\n",
    "    \n",
    "    words = ['<start>'] + words + ['<end>']\n",
    "    return ' '.join(words) \n",
    "\n",
    "with open(\"pol.txt\", 'rb') as f:\n",
    "    texts = f.read().decode('utf-8').rstrip('\\n')\n",
    "    \n",
    "pairs = [[preprocess_sentence(x) for x in pair.split('\\t')[:2]] for pair in texts.split('\\n')]\n",
    "en_str, pl_str = zip(*pairs)\n",
    "\n",
    "def tokenize(sequences):\n",
    "    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
    "    lang_tokenizer.fit_on_texts(sequences)\n",
    "    sequences = lang_tokenizer.texts_to_sequences(sequences)\n",
    "    return sequences, lang_tokenizer\n",
    "\n",
    "en_seq, en_tokenizer = tokenize(en_str)\n",
    "pl_seq, pl_tokenizer = tokenize(pl_str)\n",
    "idx_to_take = [i for i, x in enumerate(en_seq) if len(x) < 20]\n",
    "\n",
    "en_seq = [en_seq[i] for i in idx_to_take]\n",
    "pl_seq = [pl_seq[i] for i in idx_to_take]\n",
    "en_seq = tf.keras.preprocessing.sequence.pad_sequences(en_seq, padding='post')\n",
    "pl_seq = tf.keras.preprocessing.sequence.pad_sequences(pl_seq, padding='post')\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(en_seq, pl_seq, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_size = len(x_train)//5\n",
    "batch_size = 64\n",
    "\n",
    "steps_per_epoch = len(x_train) // batch_size\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "\n",
    "vocab_x_size = len(en_tokenizer.word_index) + 1\n",
    "vocab_y_size = len(pl_tokenizer.word_index) + 1\n",
    "x_valid = tf.keras.preprocessing.sequence.pad_sequences(x_valid, padding='post')\n",
    "y_valid = tf.keras.preprocessing.sequence.pad_sequences(y_valid, padding='post')\n",
    "\n",
    "dataset_tr = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(buffer_size)\n",
    "dataset_tr = dataset_tr.batch(batch_size, drop_remainder=True)\n",
    "dataset_tr = dataset_tr.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "dataset_tr_len = len([x for x, y in dataset_tr])\n",
    "\n",
    "dataset_vd = tf.data.Dataset.from_tensor_slices((x_valid, y_valid)).batch(batch_size)\n",
    "example_x, example_y = next(iter(dataset_vd))\n",
    "\n",
    "start_token = pl_tokenizer.texts_to_sequences(['<start>'])\n",
    "end_token = pl_tokenizer.texts_to_sequences(['<end>'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper_loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "\n",
    "def masked_loss(true, pred):\n",
    "    losses = helper_loss(true, pred)\n",
    "    float_mask = tf.cast(true!=0, dtype=tf.float32)\n",
    "    return tf.reduce_mean(losses * float_mask)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def training_step(encoder_sequence, decoder_sequence):\n",
    "    with tf.GradientTape() as tape:\n",
    "        decoder_outputs = model(encoder_sequence, decoder_sequence)\n",
    "        loss = model.loss(decoder_sequence, decoder_outputs)\n",
    "\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    model.optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    return loss, decoder_outputs\n",
    "\n",
    "@tf.function\n",
    "def validation_step(encoder_sequence, decoder_sequence):\n",
    "    decoder_outputs = model(encoder_sequence, decoder_sequence)\n",
    "    loss = model.loss(decoder_sequence, decoder_outputs)\n",
    "    return loss, decoder_outputs\n",
    "\n",
    "loss_met = tf.metrics.Mean()\n",
    "accu_met = tf.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "def resres(metric):\n",
    "    result = metric.result()\n",
    "    metric.reset_states()\n",
    "    return result\n",
    "\n",
    "def train(model, epochs, writer):    \n",
    "    for epoch in range(epochs):\n",
    "        time_start = time.time()\n",
    "        \n",
    "        for x, y in tqdm(dataset_tr, total=dataset_tr_len):\n",
    "            loss, outputs = training_step(x, y)\n",
    "            accu_met(y, outputs)\n",
    "            loss_met(loss)\n",
    "            \n",
    "        with writer.as_default():\n",
    "            tf.summary.scalar('training/loss', loss_met.result(), step=epoch)\n",
    "            tf.summary.scalar('training/accu', accu_met.result(), step=epoch)\n",
    "            \n",
    "        print(f\"epoch {epoch:^5} | tr loss {resres(loss_met):^8.5f} | tr accu {resres(accu_met):^8.5f} | epoch time {time.time() - time_start:^8.2f}\")\n",
    "        \n",
    "        for x, y in dataset_vd:\n",
    "            loss, outputs = validation_step(x, y)\n",
    "            accu_met(y, outputs)\n",
    "            loss_met(loss)\n",
    "            \n",
    "        with writer.as_default():\n",
    "            tf.summary.scalar('validation/loss', loss_met.result(), step=epoch)\n",
    "            tf.summary.scalar('validation/accu', accu_met.result(), step=epoch)\n",
    "            \n",
    "            outputs = tf.argmax(model(example_x), -1)\n",
    "            sample_x = '  \\n'.join(en_tokenizer.sequences_to_texts(example_x.numpy()))\n",
    "            sample_y = '  \\n'.join(pl_tokenizer.sequences_to_texts(outputs.numpy()))\n",
    "            tf.summary.text('en', sample_x, step=epoch)\n",
    "            tf.summary.text('pl', sample_y, step=epoch)\n",
    "            \n",
    "        print(f\"epoch {epoch:^5} | vd loss {resres(loss_met):^8.5f} | vd accu {resres(accu_met):^8.5f} | epoch time {time.time() - time_start:^8.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder-Decoder with 2 recurrent NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ed\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder (Encoder)            multiple                  4799753   \n",
      "_________________________________________________________________\n",
      "decoder (Decoder)            multiple                  25233525  \n",
      "=================================================================\n",
      "Total params: 30,033,278\n",
      "Trainable params: 30,033,278\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "%run EncDec.ipynb\n",
    "\n",
    "model = ED(vocab_x_size, vocab_y_size, embedding_dim, units=829, start_token=start_token, end_token=end_token, max_output_length=pl_seq.shape[1])\n",
    "output = model(example_x, example_y)\n",
    "\n",
    "model.compile(tf.optimizers.Adam(), masked_loss)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = tf.summary.create_file_writer('logs/ed_2nets_1')\n",
    "train(model, epochs=20, writer=writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder-Decoder with 1 recurrent NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"e_din_one\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        multiple                  2096384   \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      multiple                  5310976   \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    multiple                  3282825   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  19210796  \n",
      "=================================================================\n",
      "Total params: 29,900,981\n",
      "Trainable params: 29,900,981\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "%run EncDec_in1.ipynb\n",
    "\n",
    "model = EDinOne(vocab_x_size, vocab_y_size, embedding_dim, units=925, start_token=start_token, end_token=end_token, max_output_length=pl_seq.shape[1])\n",
    "output = model(example_x, example_y)\n",
    "\n",
    "model.compile(tf.optimizers.Adam(), masked_loss)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 538/538 [01:36<00:00,  5.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   0   | tr loss 2.04564  | tr accu 0.17470  | epoch time  96.15  \n",
      "epoch   0   | vd loss 1.87348  | vd accu 0.19782  | epoch time  101.49 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 538/538 [01:32<00:00,  5.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   1   | tr loss 1.73157  | tr accu 0.20796  | epoch time  92.86  \n",
      "epoch   1   | vd loss 1.79945  | vd accu 0.21111  | epoch time  96.01  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 538/538 [01:27<00:00,  6.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   2   | tr loss 1.63014  | tr accu 0.21754  | epoch time  87.92  \n",
      "epoch   2   | vd loss 1.75810  | vd accu 0.21597  | epoch time  91.11  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 538/538 [01:27<00:00,  6.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   3   | tr loss 1.54572  | tr accu 0.22237  | epoch time  87.98  \n",
      "epoch   3   | vd loss 1.72934  | vd accu 0.21724  | epoch time  91.26  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 538/538 [01:28<00:00,  6.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   4   | tr loss 1.47449  | tr accu 0.22695  | epoch time  88.13  \n",
      "epoch   4   | vd loss 1.69472  | vd accu 0.22193  | epoch time  91.38  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 538/538 [01:28<00:00,  6.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   5   | tr loss 1.35519  | tr accu 0.23133  | epoch time  88.37  \n",
      "epoch   5   | vd loss 1.47107  | vd accu 0.22769  | epoch time  91.65  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 538/538 [01:30<00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   6   | tr loss 1.10714  | tr accu 0.24786  | epoch time  90.29  \n",
      "epoch   6   | vd loss 1.28999  | vd accu 0.25027  | epoch time  93.64  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 538/538 [01:25<00:00,  6.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   7   | tr loss 0.86597  | tr accu 0.27372  | epoch time  85.20  \n",
      "epoch   7   | vd loss 1.14808  | vd accu 0.26812  | epoch time  88.77  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 538/538 [01:24<00:00,  6.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   8   | tr loss 0.60952  | tr accu 0.30274  | epoch time  84.29  \n",
      "epoch   8   | vd loss 1.07905  | vd accu 0.27846  | epoch time  87.49  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 538/538 [01:26<00:00,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   9   | tr loss 0.39800  | tr accu 0.33600  | epoch time  86.51  \n",
      "epoch   9   | vd loss 1.05574  | vd accu 0.28363  | epoch time  90.05  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 538/538 [01:25<00:00,  6.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  10   | tr loss 0.26131  | tr accu 0.36354  | epoch time  85.40  \n",
      "epoch  10   | vd loss 1.05784  | vd accu 0.28677  | epoch time  88.55  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 538/538 [01:31<00:00,  5.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  11   | tr loss 0.17944  | tr accu 0.38193  | epoch time  91.31  \n",
      "epoch  11   | vd loss 1.06844  | vd accu 0.28781  | epoch time  94.49  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 538/538 [01:28<00:00,  6.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  12   | tr loss 0.12796  | tr accu 0.39429  | epoch time  88.83  \n",
      "epoch  12   | vd loss 1.08992  | vd accu 0.28835  | epoch time  92.19  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 538/538 [01:28<00:00,  6.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  13   | tr loss 0.09463  | tr accu 0.40260  | epoch time  88.30  \n",
      "epoch  13   | vd loss 1.11685  | vd accu 0.28813  | epoch time  91.55  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 538/538 [01:28<00:00,  6.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  14   | tr loss 0.07439  | tr accu 0.40749  | epoch time  88.28  \n",
      "epoch  14   | vd loss 1.14401  | vd accu 0.28832  | epoch time  91.56  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 538/538 [01:27<00:00,  6.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  15   | tr loss 0.06168  | tr accu 0.41070  | epoch time  87.15  \n",
      "epoch  15   | vd loss 1.16926  | vd accu 0.28812  | epoch time  90.43  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 538/538 [01:23<00:00,  6.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  16   | tr loss 0.05489  | tr accu 0.41233  | epoch time  83.71  \n",
      "epoch  16   | vd loss 1.19119  | vd accu 0.28798  | epoch time  86.95  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 538/538 [01:23<00:00,  6.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  17   | tr loss 0.04978  | tr accu 0.41340  | epoch time  83.21  \n",
      "epoch  17   | vd loss 1.21111  | vd accu 0.28824  | epoch time  86.45  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 538/538 [01:23<00:00,  6.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  18   | tr loss 0.04742  | tr accu 0.41380  | epoch time  83.41  \n",
      "epoch  18   | vd loss 1.23902  | vd accu 0.28799  | epoch time  86.69  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 538/538 [01:25<00:00,  6.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  19   | tr loss 0.04661  | tr accu 0.41371  | epoch time  85.73  \n",
      "epoch  19   | vd loss 1.26553  | vd accu 0.28655  | epoch time  89.35  \n"
     ]
    }
   ],
   "source": [
    "writer = tf.summary.create_file_writer('logs/ed_in1_1')\n",
    "train(model, epochs=20, writer=writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder-Decoder with attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ed_attention\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder (Encoder)            multiple                  4322384   \n",
      "_________________________________________________________________\n",
      "decoder (Decoder)            multiple                  25706301  \n",
      "=================================================================\n",
      "Total params: 30,028,685\n",
      "Trainable params: 30,028,685\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "%run EncDec_attention.ipynb\n",
    "\n",
    "model = ED_attention(vocab_x_size, vocab_y_size, embedding_dim, units=742, start_token=start_token, end_token=end_token, max_output_length=pl_seq.shape[1])\n",
    "output = model(example_x, example_y)\n",
    "\n",
    "model.compile(tf.optimizers.Adam(), masked_loss)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 538/538 [05:30<00:00,  1.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   0   | tr loss 2.00605  | tr accu 0.17915  | epoch time  330.63 \n",
      "epoch   0   | vd loss 1.86187  | vd accu 0.19627  | epoch time  380.86 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 538/538 [04:44<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   1   | tr loss 1.77607  | tr accu 0.20154  | epoch time  284.62 \n",
      "epoch   1   | vd loss 1.79043  | vd accu 0.21105  | epoch time  307.49 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 538/538 [04:53<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   2   | tr loss 1.62613  | tr accu 0.21838  | epoch time  293.46 \n",
      "epoch   2   | vd loss 1.58607  | vd accu 0.22241  | epoch time  316.29 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 538/538 [04:45<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   3   | tr loss 1.36625  | tr accu 0.23445  | epoch time  285.82 \n",
      "epoch   3   | vd loss 1.33839  | vd accu 0.24252  | epoch time  308.60 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 538/538 [04:45<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   4   | tr loss 1.06139  | tr accu 0.26009  | epoch time  285.33 \n",
      "epoch   4   | vd loss 1.12573  | vd accu 0.26359  | epoch time  308.23 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 538/538 [04:31<00:00,  1.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   5   | tr loss 0.75171  | tr accu 0.28614  | epoch time  271.49 \n",
      "epoch   5   | vd loss 1.02695  | vd accu 0.27690  | epoch time  295.24 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 538/538 [04:45<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   6   | tr loss 0.49720  | tr accu 0.31782  | epoch time  285.43 \n",
      "epoch   6   | vd loss 0.99030  | vd accu 0.28283  | epoch time  308.30 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 538/538 [04:48<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   7   | tr loss 0.32664  | tr accu 0.34875  | epoch time  288.21 \n",
      "epoch   7   | vd loss 0.98802  | vd accu 0.28814  | epoch time  309.44 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 538/538 [04:29<00:00,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   8   | tr loss 0.23423  | tr accu 0.36837  | epoch time  269.62 \n",
      "epoch   8   | vd loss 0.99067  | vd accu 0.28977  | epoch time  292.40 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 538/538 [04:45<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   9   | tr loss 0.17576  | tr accu 0.38125  | epoch time  285.45 \n",
      "epoch   9   | vd loss 1.00962  | vd accu 0.29072  | epoch time  308.24 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 538/538 [04:44<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  10   | tr loss 0.13503  | tr accu 0.39119  | epoch time  284.61 \n",
      "epoch  10   | vd loss 1.01984  | vd accu 0.29027  | epoch time  307.38 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 538/538 [04:44<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  11   | tr loss 0.10395  | tr accu 0.39892  | epoch time  284.40 \n",
      "epoch  11   | vd loss 1.04203  | vd accu 0.29070  | epoch time  307.22 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 538/538 [04:52<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  12   | tr loss 0.08421  | tr accu 0.40384  | epoch time  292.46 \n",
      "epoch  12   | vd loss 1.06249  | vd accu 0.29109  | epoch time  317.15 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 538/538 [04:35<00:00,  1.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  13   | tr loss 0.07152  | tr accu 0.40706  | epoch time  275.09 \n",
      "epoch  13   | vd loss 1.08758  | vd accu 0.29153  | epoch time  296.68 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 538/538 [04:47<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  14   | tr loss 0.06289  | tr accu 0.40911  | epoch time  287.92 \n",
      "epoch  14   | vd loss 1.11297  | vd accu 0.29155  | epoch time  312.41 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 538/538 [04:41<00:00,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  15   | tr loss 0.05795  | tr accu 0.41057  | epoch time  281.56 \n",
      "epoch  15   | vd loss 1.13407  | vd accu 0.29116  | epoch time  303.60 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▎                                                                                | 9/538 [00:04<04:48,  1.83it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-6581737f5482>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mwriter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_file_writer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'logs/ed_attention_1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwriter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-4-ab24f63dd7c0>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, epochs, writer)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset_tr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdataset_tr_len\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m             \u001b[0maccu_met\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m             \u001b[0mloss_met\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    485\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 487\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    488\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1821\u001b[0m     \u001b[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1823\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1824\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1825\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1141\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1143\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[1;32m-> 1224\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1225\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "writer = tf.summary.create_file_writer('logs/ed_attention_1')\n",
    "train(model, epochs=20, writer=writer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
